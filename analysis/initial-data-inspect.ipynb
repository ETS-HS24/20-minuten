{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:39:16.897355Z",
     "start_time": "2024-10-16T14:39:16.889139Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data_path = \"./data/20min-test-query-2020-jan-jun/raw-data/\"\n",
    "raw_file_name = \"cd558cca-53cb-4ff9-a3f5-89f70e139051__2024_10_13T18_23_54.tsv\"\n",
    "\n",
    "# We can not share the full swissdox dataset, hence control the jupyter output while exporting\n",
    "EXPORT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:39:18.404541Z",
     "start_time": "2024-10-16T14:39:17.608308Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import lxml.html\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:39:20.769144Z",
     "start_time": "2024-10-16T14:39:19.383370Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(raw_data_path, raw_file_name)) as file:\n",
    "    raw_file = file.readlines()\n",
    "\n",
    "print(raw_file[0])\n",
    "if EXPORT:\n",
    "    print(raw_file[1].replace(\"\\t\", \" <tab> \")[:60])\n",
    "else:\n",
    "    print(raw_file[1].replace(\"\\t\", \" <tab> \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:39:23.961054Z",
     "start_time": "2024-10-16T14:39:22.678961Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(raw_data_path, raw_file_name), sep=\"\\t\")\n",
    "print(df.shape)\n",
    "print(df.head(1).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:39:26.008042Z",
     "start_time": "2024-10-16T14:39:25.977988Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:39:31.305975Z",
     "start_time": "2024-10-16T14:39:31.291980Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_nan_columns = [\"rubric\", \"regional\", \"subhead\"]\n",
    "df = df.drop(drop_nan_columns, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:39:33.458392Z",
     "start_time": "2024-10-16T14:39:33.439174Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doctype\n",
    "doctype\n",
    "doctype_description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"doctype_description\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not info which rubric this is from... Does this have to be scraped?    \n",
    "Would be interesting but is it relevant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML Tag statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_counters(counter_list):\n",
    "    accumulator_counter = Counter()\n",
    "    for counter in counter_list:\n",
    "        accumulator_counter += counter\n",
    "\n",
    "    return accumulator_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de = df[df[\"language\"] == \"de\"]\n",
    "df_fr = df[df[\"language\"] == \"fr\"]\n",
    "\n",
    "print(f\"all: {df.shape}, de: {df_de.shape}, fr: {df_fr.shape}\")\n",
    "print(f\"difference?: {len(df) - len(df_de) - len(df_fr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de.content[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_de[\"content\"].iloc[0:10]:\n",
    "    print(row) if not EXPORT else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_html_tag_occurence = lambda content: Counter({element.tag for element in lxml.html.fromstring(content).iter()})\n",
    "tag_occurence = list(df_de[\"content\"].apply(get_html_tag_occurence))\n",
    "accumulator_occurence = accumulate_counters(tag_occurence)\n",
    "pd.DataFrame(accumulator_occurence, index=[\"counts\"]).sort_values(by=[\"counts\"], ascending=False, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Every article has the following:\n",
    "    * tx -> whole text wrapped\n",
    "    * ld -> lead text (except one article)\n",
    "    * p -> multiple text elements\n",
    "        * If there is a last element with brackets this might be one or multiple authors:\n",
    "            * `<p>(SDA)</p></tx>`\n",
    "\n",
    "\n",
    "* The other tags should be checked if there is something relevant extractable\n",
    "    * zt -> zwischentitel(subheading)\n",
    "    * a -> anchor -> links to \n",
    "        * other websites or \n",
    "        * other articles `<a href=\"#showid=305209&amp;index=0\">La Cumbre-Ausbruch bedroht seltene Tierarten</a>` -> not sure what this is referencing\n",
    "        * other articles `<a href=\"https://www.20min.ch/ausland/news/story/Saemtliche-Fluege-wegen-Vulkanausbruch-anulliert-22651640\">Taal</a>`\n",
    "    * br -> breaks\n",
    "        * These breaks are also part of twitter messages, as indicated by `<ka>` <br/>\n",
    "            `<ka><p>¡Hey! ??<br/><br/>Tiempo de jugar... ??<br/><br/>¿Nos`...\n",
    "    * ka -> external embeddings?\n",
    "        * also a \"darum gehts\" box as indicated by:\n",
    "            * `<ka><p>Darum gehts</p><p>`\n",
    "            * each bullet point has their own `<p>...</p>`    \n",
    "    * lg -> lead graphic (text of first picture on the article) -> include/exclude?\n",
    "    * au -> author full name (not short name as in last p element)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it look similar for the french version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_html_tag_occurence = lambda content: Counter({element.tag for element in lxml.html.fromstring(content).iter()})\n",
    "tag_occurence = list(df_fr[\"content\"].apply(get_html_tag_occurence))\n",
    "accumulator_occurence = accumulate_counters(tag_occurence)\n",
    "pd.DataFrame(accumulator_occurence, index=[\"counts\"]).sort_values(by=[\"counts\"], ascending=False, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes it looks simlilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_html_tag_counts = lambda content: Counter(element.tag for element in lxml.html.fromstring(content).iter())\n",
    "tags_counts = list(df_de[\"content\"].apply(get_html_tag_counts))\n",
    "\n",
    "tags_counts[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulator_counter = accumulate_counters(tags_counts)\n",
    "plot_df = pd.DataFrame(accumulator_counter, index=[\"counts\"]).sort_values(by=[\"counts\"], ascending=False, axis=1)\n",
    "plot_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(plot_df.drop([\"p\"], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us also extract the following:\n",
    "\n",
    "* `<ld>`: lead text\n",
    "* last ``<p>`` if encased in (): author(s) \n",
    "* ``<zt>``: subheadings\n",
    "* ``<ka>``: differentiate if external website or not\n",
    "\n",
    "what is lg and au?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lg(article:str):\n",
    "    soup = BeautifulSoup(article)\n",
    "    if soup.lg:\n",
    "        return soup.lg.string\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "series_lg = df_de[\"content\"].apply(get_lg)\n",
    "\n",
    "for row in series_lg[~series_lg.isnull()].iloc[0:3]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_au(article:str):\n",
    "    soup = BeautifulSoup(article)\n",
    "    if soup.au:\n",
    "        return soup.au.string\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "series_au = df_de[\"content\"].apply(get_au)\n",
    "\n",
    "for row in series_au[~series_au.isnull()].iloc[0:3]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"articles with multiple authors:\", series_au[~series_au.isnull()].str.contains(\",\").sum())\n",
    "series_au.groupby(series_au).count().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lead(article:str ):\n",
    "    soup = BeautifulSoup(article)\n",
    "    if soup.ld:\n",
    "        return soup.ld.string\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de[\"content\"].apply(get_lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_authors(article:str):\n",
    "    \"\"\" If the last <p> element encapsulates any text with \"()\" then \n",
    "        this text is split by eitehr \",\" or \"/\" into a list of authors.\"\"\"\n",
    "    soup = BeautifulSoup(article)\n",
    "    if soup.p:\n",
    "        last_p =  soup.find_all(\"p\")[-1].text\n",
    "        if last_p[0] == \"(\" and last_p[-1] == \")\":\n",
    "            inner_last_p = last_p[1:-1]\n",
    "            if \",\" in inner_last_p:\n",
    "                return_value = inner_last_p.split(\",\")\n",
    "            elif \"/\" in last_p[1:-1]:\n",
    "                return_value = inner_last_p.split(\"/\")\n",
    "            else:\n",
    "                return_value = [inner_last_p]\n",
    "\n",
    "            # sanity check, there should hopefully not be a broken up string\n",
    "            if len(return_value) > 3:\n",
    "                print(return_value)\n",
    "                \n",
    "            return return_value\n",
    "        else: \n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_per_article = df_de[\"content\"].apply(get_authors)\n",
    "num_authors = authors_per_article.apply(lambda x: len(x) if x else 0)\n",
    "sns.histplot(num_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_per_article.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate nonstandard authors that are not 2 or 3 chars\n",
    "for r in authors_per_article:\n",
    "    if not r:\n",
    "        continue\n",
    "\n",
    "    if not any([True for x in r if \"/\" in x]):\n",
    "        if len(r) == 1 and not (len(r[0]) == 3 or len(r[0]) == 2 ):\n",
    "            print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check overlap of `<au>` and extracted authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total matches are more than the samples in the dataframe: \", authors_per_article.isna().sum() +series_au.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of overlapping: \", sum(~authors_per_article.isna() & ~series_au.isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of both empty: \", sum(authors_per_article.isna() & series_au.isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlap is basically SDA, Reuters and DPA... in series_au, authors it is people\n",
    "authors_per_article[~authors_per_article.isna() & ~series_au.isna()].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"overlap example:\")\n",
    "for url in df_de[authors_per_article.isna() & series_au.isna()][\"article_link\"].iloc[-10:]:\n",
    "    print(url)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"for row in df_de[\"content\"].iloc[0:10]:\n",
    "    print(row)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subheadings(article:str):\n",
    "    soup = BeautifulSoup(article)\n",
    "    if soup.zt:\n",
    "        return [zt.text for zt in soup.find_all(\"zt\")]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df_fr[\"content\"].apply(get_subheadings)\n",
    "res[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion on HTML tags\n",
    "\n",
    "### Available tags:\n",
    "* tx -> whole text wrapped\n",
    "    * just remove the tag itself\n",
    "* ld -> lead text\n",
    "    * extract to column\n",
    "* p -> multiple text elements\n",
    "    * just remove the tags\n",
    "* p -> last element iff matches authors\n",
    "    * remove the authors and extract to column\n",
    "    \n",
    "* zt -> zwischentitel(subheading)\n",
    "    * extract to column\n",
    "* a -> anchor\n",
    "    * remove the urls but keep the annotated text within tag\n",
    "* br -> breaks\n",
    "    * remove the tags\n",
    "* ka -> external embeddings?\n",
    "    * remove the tags\n",
    "* lg -> lead graphic (text of first picture on the article) -> include/exclude?\n",
    "    * strip out content of tag, this is in reference to one of many images\n",
    "* au -> author full name (not short name as in last p element)\n",
    "    * for now: create second column since the overlap with extracted authors from last `<p>` and `<au>` is small but `SDA`, `Reuters`... vs `<human name>`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Columns should be:\n",
    "* id\n",
    "* pubtime\n",
    "* language\n",
    "* char_count\n",
    "* dateline\n",
    "* head\n",
    "* article_link\n",
    "* content\n",
    "* lead_text\n",
    "* subheadings\n",
    "* author_extracted (extracted from last `<p>`)\n",
    "* author (extracted from `<au>` tag)\n",
    "* text (cleaned ``content``)\n",
    "    * remove just tags:\n",
    "        * `<tx>`\n",
    "        * `<br>`\n",
    "        * `<ka>`\n",
    "    * remove substring from content\n",
    "        * last `<p>` if it is a match for author filter\n",
    "        * urls from `<a>` tag -> check if general html tag remover also does this easily\n",
    "        * `<lg>` text since it is related to the image not the article."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
