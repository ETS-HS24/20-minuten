{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Change to main folder of project, run only once!\n",
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-13 10:33:28,629 | [SentenceTransformer.py:216] INFO | Load pretrained SentenceTransformer: sentence-transformers/LaBSE\n",
      "topics of loaded model 11\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import tpe, hp, fmin, STATUS_OK, Trials, rand\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from top2vec import Top2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout,\n",
    "                    level=logging.INFO,\n",
    "                    format='%(asctime)s | [%(filename)s:%(lineno)d] %(levelname)s | %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#dataset_name = \"./models/top2vec/labse-fr-dataset\"\n",
    "model_path = \"./models/top2vec/labse-three-year\"\n",
    "\n",
    "pretrained_model = SentenceTransformer('sentence-transformers/LaBSE', device=\"cpu\")  \n",
    "top2vec_model = Top2Vec.load(os.path.normpath(model_path))\n",
    "top2vec_model.set_embedding_model(pretrained_model)\n",
    "print(\"topics of loaded model\", top2vec_model.get_num_topics())\n",
    "loaded_embeddings = top2vec_model.document_vectors\n",
    "\n",
    "\n",
    "def hyperparameter_tuning(params, model=top2vec_model, target_clusters=50):\n",
    "    umap_args = {\n",
    "        \"n_neighbors\": params[\"n_neighbors\"],\n",
    "        \"n_components\": params[\"n_components\"],\n",
    "        \"metric\": params[\"umap_metric\"]\n",
    "    }\n",
    "    hdbscan_args = {\n",
    "        'min_cluster_size': params[\"min_cluster_size\"],\n",
    "        'metric': params[\"hdbscan_metric\"],\n",
    "        'cluster_selection_method': params[\"cluster_selection_method\"]\n",
    "    }\n",
    "    \n",
    "    model.compute_topics(\n",
    "        umap_args=umap_args,\n",
    "        gpu_umap=True,\n",
    "        hdbscan_args=hdbscan_args,\n",
    "        gpu_hdbscan=False,\n",
    "        topic_merge_delta=params[\"topic_merge_delta\"]\n",
    "    )\n",
    "    \n",
    "    n_clusters = model.get_num_topics()\n",
    "\n",
    "    logging.debug(f\"Found {n_clusters} labels\")\n",
    "    loss = np.abs(target_clusters - n_clusters)\n",
    "\n",
    "\n",
    "    return {\"status\": STATUS_OK, \"loss\": loss, \"n_clusters\": n_clusters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trials object\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [5, 10, 15, 20, 25, 40, 45, 55]\n",
    "n_components = [3, 5, 7, 9, 13, 17, 20, 23]\n",
    "umap_metric = [\"euclidean\", \"cosine\"]\n",
    "min_cluster_size = [5, 10, 15, 20, 25]\n",
    "hdbscan_metric = [\"euclidean\"]\n",
    "cluster_selection_method = [\"eom\", \"leaf\"]\n",
    "topic_merge_delta = [0.05, 0.1, 0.15]\n",
    "\n",
    "space = {\n",
    "    \"n_neighbors\": hp.choice(\"n_neighbors\", n_neighbors),\n",
    "    \"n_components\": hp.choice(\"n_components\", n_components),\n",
    "    \"umap_metric\": hp.choice(\"umap_metric\", umap_metric),\n",
    "    \"min_cluster_size\": hp.choice(\"min_cluster_size\", min_cluster_size),\n",
    "    \"hdbscan_metric\": hp.choice(\"hdbscan_metric\", hdbscan_metric), \n",
    "    \"cluster_selection_method\": hp.choice(\"cluster_selection_method\", cluster_selection_method),\n",
    "    \"topic_merge_delta\": hp.choice(\"topic_merge_delta\", topic_merge_delta),\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "best = fmin(\n",
    "    fn=hyperparameter_tuning,\n",
    "    space = space, \n",
    "    algo=tpe.suggest, #tpe.rand.suggest\n",
    "    max_evals=600, #200, \n",
    "    trials=trials,\n",
    "    trials_save_file=\"./trials-save-file.trials\"\n",
    ")\n",
    "\n",
    "print(\"Best: {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"trials-save-file.trials\", \"rb\") as f:\n",
    "    t_loaded = pickle.load(f)\n",
    "\n",
    "t_loaded.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_selection_method</th>\n",
       "      <th>hdbscan_metric</th>\n",
       "      <th>min_cluster_size</th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>topic_merge_delta</th>\n",
       "      <th>umap_metric</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster_selection_method hdbscan_metric  min_cluster_size  n_components  \\\n",
       "568                      eom      euclidean                20             5   \n",
       "577                      eom      euclidean                20             5   \n",
       "576                      eom      euclidean                20             5   \n",
       "555                      eom      euclidean                20             5   \n",
       "563                      eom      euclidean                20             5   \n",
       "\n",
       "     n_neighbors  topic_merge_delta umap_metric  loss  \n",
       "568           40               0.05   euclidean   5.0  \n",
       "577           40               0.05   euclidean   7.0  \n",
       "576           40               0.05   euclidean   7.0  \n",
       "555           40               0.10   euclidean   8.0  \n",
       "563           40               0.10   euclidean   8.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def unpack(x):\n",
    "    if x:\n",
    "        return x[0]\n",
    "    return np.nan\n",
    "\n",
    "trials_df = pd.DataFrame([pd.Series(t[\"misc\"][\"vals\"]).apply(unpack) for t in t_loaded])\n",
    "trials_df[\"loss\"] = [t[\"result\"].get(\"loss\", 9999) for t in t_loaded]\n",
    "\n",
    "trials_df[\"n_neighbors\"] = trials_df[\"n_neighbors\"].replace(list(range(len(n_neighbors))), n_neighbors)\n",
    "trials_df[\"n_components\"] = trials_df[\"n_components\"].replace(list(range(len(n_components))), n_components)\n",
    "trials_df[\"umap_metric\"] = trials_df[\"umap_metric\"].replace(list(range(len(umap_metric))), umap_metric)\n",
    "trials_df[\"min_cluster_size\"] = trials_df[\"min_cluster_size\"].replace(list(range(len(min_cluster_size))), min_cluster_size)\n",
    "trials_df[\"hdbscan_metric\"] = trials_df[\"hdbscan_metric\"].replace(list(range(len(hdbscan_metric))), hdbscan_metric)\n",
    "trials_df[\"cluster_selection_method\"] = trials_df[\"cluster_selection_method\"].replace(list(range(len(cluster_selection_method))), cluster_selection_method)\n",
    "trials_df[\"topic_merge_delta\"] = trials_df[\"topic_merge_delta\"].replace(list(range(len(topic_merge_delta))), topic_merge_delta)\n",
    "\n",
    "trials_df.sort_values(by=\"loss\", inplace=True)\n",
    "\n",
    "\n",
    "experiment_params = {\n",
    "    \"n_neighbors\": n_neighbors,\n",
    "    \"n_components\": n_components,\n",
    "    \"umap_metric\": umap_metric,\n",
    "    \"min_cluster_size\": min_cluster_size,\n",
    "    \"hdbscan_metric\": hdbscan_metric,\n",
    "    \"cluster_selection_method\": cluster_selection_method,\n",
    "    \"topic_merge_delta\": topic_merge_delta,\n",
    "}\n",
    "\n",
    "experiment_start = [t for t in t_loaded][0][\"book_time\"]\n",
    "experiment_end = [t for t in t_loaded][-1][\"book_time\"]\n",
    "timestamp_start = experiment_start.strftime('%Y-%m-%d-%H-%M-%S')\n",
    "timestamp_end = experiment_start.strftime('%Y-%m-%d-%H-%M-%S')\n",
    "experiment_folder = os.path.normpath(f\"./analysis/umap-hdbet-hyperopt-{timestamp_start}-{timestamp_end}/\")\n",
    "Path(experiment_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(experiment_folder, \"model-path.txt\"), \"w\") as f:\n",
    "    f.write(model_path)\n",
    "\n",
    "with open(os.path.join(experiment_folder, \"optimization-space.json\"), \"w\") as f:\n",
    "    json.dump(experiment_params, f)\n",
    "\n",
    "trials_df.to_csv(os.path.join(experiment_folder, \"optimization-results.csv\"))\n",
    "\n",
    "with open(os.path.join(experiment_folder, \"trials.pickle\"), 'wb') as handle:\n",
    "    pickle.dump(trials, handle)\n",
    "\n",
    "\n",
    "trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_selection_method</th>\n",
       "      <th>hdbscan_metric</th>\n",
       "      <th>min_cluster_size</th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>topic_merge_delta</th>\n",
       "      <th>umap_metric</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster_selection_method hdbscan_metric  min_cluster_size  n_components  \\\n",
       "568                      eom      euclidean                20             5   \n",
       "577                      eom      euclidean                20             5   \n",
       "576                      eom      euclidean                20             5   \n",
       "555                      eom      euclidean                20             5   \n",
       "563                      eom      euclidean                20             5   \n",
       "\n",
       "     n_neighbors  topic_merge_delta umap_metric  loss  \n",
       "568           40               0.05   euclidean   5.0  \n",
       "577           40               0.05   euclidean   7.0  \n",
       "576           40               0.05   euclidean   7.0  \n",
       "555           40               0.10   euclidean   8.0  \n",
       "563           40               0.10   euclidean   8.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload from disk\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(os.path.normpath(\"./analysis/umap-hdbet-hyperopt-2024-11-11-20-40-46-2024-11-11-20-40-46/optimization-results.csv\"), index_col=0)\n",
    "# remove outliers/nan loss\n",
    "df = df[df[\"loss\"] != 9999]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_filter = df.loss < 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_selection_method</th>\n",
       "      <th>hdbscan_metric</th>\n",
       "      <th>min_cluster_size</th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>topic_merge_delta</th>\n",
       "      <th>umap_metric</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster_selection_method hdbscan_metric  min_cluster_size  n_components  \\\n",
       "568                      eom      euclidean                20             5   \n",
       "577                      eom      euclidean                20             5   \n",
       "576                      eom      euclidean                20             5   \n",
       "555                      eom      euclidean                20             5   \n",
       "563                      eom      euclidean                20             5   \n",
       "\n",
       "     n_neighbors  topic_merge_delta umap_metric  loss  \n",
       "568           40               0.05   euclidean   5.0  \n",
       "577           40               0.05   euclidean   7.0  \n",
       "576           40               0.05   euclidean   7.0  \n",
       "555           40               0.10   euclidean   8.0  \n",
       "563           40               0.10   euclidean   8.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df_loss_filter].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in this selection: 188\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def variable_plot(variable, df=df, df_loss_filter = df.loss < 50):\n",
    "    print(f\"Visualizing the variable: {variable} vs loss.\")\n",
    "    print(df[df_loss_filter][[variable]].value_counts())\n",
    "    df[df_loss_filter][[variable, \"loss\"]].boxplot(by=variable, figsize=(7,2))\n",
    "    plt.title(f\"loss grouped by {variable}\")\n",
    "    plt.suptitle('')\n",
    "    Path(\"./analysis/graphics/\").mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(f\"./graphics/{variable}.pdf\")\n",
    "\n",
    "def get_quantiles(variable:str, keys:list):\n",
    "    print(df[df_loss_filter][[variable, \"loss\"]].groupby(variable).quantile([0.25, 0.5, 0.75]).loc[keys])\n",
    "\n",
    "print(f\"Number of samples in this selection: {len(df[df_loss_filter])}\")\n",
    "variables = [\n",
    "    \"n_neighbors\",\n",
    "    \"n_components\",\n",
    "    \"umap_metric\",\n",
    "    \"min_cluster_size\",\n",
    "    \"hdbscan_metric\",\n",
    "    \"cluster_selection_method\",\n",
    "    \"topic_merge_delta\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_plot(variables[0])\n",
    "get_quantiles(variables[0], [40, 45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_plot(variables[1])\n",
    "get_quantiles(variables[1], [3, 5, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_plot(variables[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_plot(variables[3])\n",
    "get_quantiles(variables[3], [20, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_plot(variables[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_plot(variables[6])\n",
    "get_quantiles(variables[6], [0.05, 0.1, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_selection_method</th>\n",
       "      <th>hdbscan_metric</th>\n",
       "      <th>min_cluster_size</th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>topic_merge_delta</th>\n",
       "      <th>umap_metric</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>eom</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster_selection_method hdbscan_metric  min_cluster_size  n_components  \\\n",
       "568                      eom      euclidean                20             5   \n",
       "\n",
       "     n_neighbors  topic_merge_delta umap_metric  loss  \n",
       "568           40               0.05   euclidean   5.0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "For totaly 578 experiments we are investigating the subset of parameters that have a loss of lower than 50. This are 188 experiments in total.\n",
    "\n",
    "n_neighbors:  \n",
    "n_neighbors 40 has the lowest median loss with 28 but is still within the 25% quantile of 22 of the 45 n_neighbors group. We can not for sure conclude the optimal parameter but we should tend towards 40.\n",
    "\n",
    "n_components:  \n",
    "For 5 components we clearly see that the median with 17.5 loss is outside of every other variables 25% quantile for the filtered experiments. We conclude that we shall choose 5 components.\n",
    "\n",
    "umap_metric:  \n",
    "No significant difference can be shown between cosine and euclidean. The euclidean metric shows a bigger variance\n",
    "\n",
    "min_cluste_size:  \n",
    "For the 188 filtered trials 5 and 15 only represent 1, respective 2 samples. This leads us to believe that those are just outliers. For 20 and 25 min_cluster_size we can not discern a parameter that would suit better. We should take both of them into consideration.\n",
    "\n",
    "hdbscans cluster_selection_method:  \n",
    "For this variable we only see eom within the filtered samples. Leaf does not appear to be represented. We shall choose the eom method.\n",
    "\n",
    "topic_merge_delta:  \n",
    "The median loss for the three parameters of 0.05, 0.1 and 0.15 is 38 for the first two and and 39 for the latter. What whe observe is that the number of samples for the parameter 0.1 is 149 while 0.5 and 0.15 have a count of 21 and 18 respectively. This indicates that 0.1 is overrepresented in the experiments, so we shall choose 0.1.\n",
    "\n",
    "According to the optimization, the smallest loss was produced with the following parameters: cluster_selection_method=eom, hdbscan_metric=euclidean, min_cluster_size=20, n_components=5, n_neighbors=40, topic_merge_delta=0.05, umap_metric=euclidean\n",
    "\n",
    "Parameter decision:  \n",
    "We shall change the selection of umap_metric from euclidean to cosine since this might reduce variance and is the default in the top2vec pipeline. We shall change the selection of topic_merge_delta from 0.05 to 0.1 since for 0.05 there are only 21 observations. This might be an outlier. So we set topic_merge_delta to top2vec's default value 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refit the model to optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_args = {\n",
    "    \"n_neighbors\": 40,\n",
    "    \"n_components\": 5,\n",
    "    \"metric\": \"cosine\",\n",
    "}\n",
    "hdbscan_args = {\n",
    "    'min_cluster_size': 20,\n",
    "    'metric': \"euclidean\",\n",
    "    'cluster_selection_method': \"eom\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from top2vec import Top2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout,\n",
    "                    level=logging.INFO,\n",
    "                    format='%(asctime)s | [%(filename)s:%(lineno)d] %(levelname)s | %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "model_path = \"./models/top2vec/labse-three-year\"\n",
    "model_path_refit = \"./models/top2vec/labse-three-year-optimized\"\n",
    "\n",
    "pretrained_model = SentenceTransformer('sentence-transformers/LaBSE', device=\"cpu\")  \n",
    "top2vec_model = Top2Vec.load(os.path.normpath(model_path))\n",
    "top2vec_model.set_embedding_model(pretrained_model)\n",
    "print(\"topics of loaded model\", top2vec_model.get_num_topics())\n",
    "\n",
    "\n",
    "top2vec_model.compute_topics(\n",
    "    umap_args=umap_args,\n",
    "    gpu_umap=False,\n",
    "    hdbscan_args=hdbscan_args,\n",
    "    gpu_hdbscan=False,\n",
    ")\n",
    "\n",
    "n_clusters = top2vec_model.get_num_topics()\n",
    "print(\"topics of recomputed model\", n_clusters)\n",
    "topic_sizes, topic_nums = top2vec_model.get_topic_sizes()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(list(range(len(topic_sizes))), topic_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.service._topic_modeling import TopicModelingService\n",
    "\n",
    "model_path_refit = \"./models/top2vec/labse-three-year-optimized\"\n",
    "saved_path = TopicModelingService.save_top2vec_model(model=top2vec_model, model_save_path=model_path_refit)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
